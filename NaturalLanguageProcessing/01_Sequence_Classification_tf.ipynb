{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sequence Classification**\n",
        "Sequence classification is a natural language processing task of assigning a label or class to a given text.\n",
        "\n",
        "We shall fine-tune a BERT model using TensorFlow to identify if a given two sentences are paraphrases or not (i.e., if both sentences mean the same thing) using MRPC (Microsoft Research Paraphrase Corpus) dataset."
      ],
      "metadata": {
        "id": "SNt-v3Afsne8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Install and Import Required Libraries**"
      ],
      "metadata": {
        "id": "3p__9Rcskcg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers evaluate"
      ],
      "metadata": {
        "id": "NYV-gTN79Z4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, DataCollatorWithPadding\n",
        "from datasets import load_dataset\n",
        "from evaluate import load"
      ],
      "metadata": {
        "id": "JHTqsIH6dOcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Load Data**"
      ],
      "metadata": {
        "id": "hymxgjAvzjHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = load_dataset('glue', 'mrpc')"
      ],
      "metadata": {
        "id": "SXg4smJzeA0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yErlky3WeVzz",
        "outputId": "927af527-e2e2-4660-c07d-add5cd83ece3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 3668\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 408\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 1725\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Preprocess Data**"
      ],
      "metadata": {
        "id": "5ZjuZoSiKy48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "M0mXEBCK0SYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer_function(example):\n",
        "  return tokenizer(example['sentence1'], example['sentence2'], truncation=True)\n",
        "\n",
        "tokenized_dataset = raw_dataset.map(tokenizer_function, batched=True)"
      ],
      "metadata": {
        "id": "wlq124I4erGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpGyJWYT0_1g",
        "outputId": "b60a4ec5-3b15-457c-cebf-ea4afbdf8380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 3668\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 408\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 1725\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors='tf')\n",
        "\n",
        "tf_train_dataset = tokenized_dataset['train'].to_tf_dataset(\n",
        "    columns = ['input_ids', 'token_type_ids', 'attention_mask'],\n",
        "    label_cols = ['label'],\n",
        "    collate_fn = data_collator,\n",
        "    shuffle = True,\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "tf_validation_dataset = tokenized_dataset['validation'].to_tf_dataset(\n",
        "    columns = ['input_ids', 'token_type_ids', 'attention_mask'],\n",
        "    label_cols = ['label'],\n",
        "    collate_fn = data_collator,\n",
        "    shuffle = False,\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "tf_test_dataset = tokenized_dataset['test'].to_tf_dataset(\n",
        "    columns = ['input_ids', 'token_type_ids', 'attention_mask'],\n",
        "    label_cols = ['label'],\n",
        "    collate_fn = data_collator,\n",
        "    shuffle = False,\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "XOaVaYOdfNba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Define and Fine-tune the Model**"
      ],
      "metadata": {
        "id": "PnI--sNYLXer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)"
      ],
      "metadata": {
        "id": "QmDe5mPmLC28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "lr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "history = model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=num_epochs, verbose=1)"
      ],
      "metadata": {
        "id": "h8BWvg3LheVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3369b8-2b57-47d6-c6ba-b78f0dbe2a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "459/459 [==============================] - 162s 212ms/step - loss: 0.6052 - accuracy: 0.6919 - val_loss: 0.5469 - val_accuracy: 0.7230\n",
            "Epoch 2/5\n",
            "459/459 [==============================] - 75s 164ms/step - loss: 0.4261 - accuracy: 0.8146 - val_loss: 0.3581 - val_accuracy: 0.8456\n",
            "Epoch 3/5\n",
            "459/459 [==============================] - 72s 157ms/step - loss: 0.1890 - accuracy: 0.9310 - val_loss: 0.4209 - val_accuracy: 0.8431\n",
            "Epoch 4/5\n",
            "459/459 [==============================] - 72s 156ms/step - loss: 0.0573 - accuracy: 0.9806 - val_loss: 0.6059 - val_accuracy: 0.8456\n",
            "Epoch 5/5\n",
            "459/459 [==============================] - 75s 163ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.6497 - val_accuracy: 0.8529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Predict using the Fine-tuned Model**\n",
        "\n"
      ],
      "metadata": {
        "id": "KO0qmwwPL11f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(tf_test_dataset)['logits']\n",
        "class_preds = np.argmax(predictions, axis=-1)\n",
        "class_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAVkxy6ykGVs",
        "outputId": "c6e679fd-a8ee-4f17-8818-8148bd1bd159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "216/216 [==============================] - 16s 58ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Compute Metrics**"
      ],
      "metadata": {
        "id": "jXUwWK_ykpUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load('glue', 'mrpc')"
      ],
      "metadata": {
        "id": "eYJZPbupmVR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=class_preds, references=tokenized_dataset['test']['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6RdgJ-IfOlq",
        "outputId": "d29f7366-634a-45e7-d9de-c8ec31497ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8394202898550724, 'f1': 0.8834665544804374}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}