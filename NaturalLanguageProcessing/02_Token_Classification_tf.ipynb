{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Token Classification**\n",
        "Token classification is a natural language understanding task in which a label is assigned to individual tokens in a sentence. Some popular token classification tasks are Named Entity Recognition (NER) and Part-of-Speech tagging (POS).\n",
        "\n",
        "We shall fine-tune a BERT model using TensorFlow on a NER task using CoNLL-2003 dataset, which contains news stories from Reuters."
      ],
      "metadata": {
        "id": "rB4U8qeMNjA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Install and Import Required Libraries**"
      ],
      "metadata": {
        "id": "zohum7L9WRb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers evaluate seqeval"
      ],
      "metadata": {
        "id": "V9iHF6C5RTJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "misxKoHRNSF_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "from transformers import AutoTokenizer, DataCollatorForTokenClassification, TFAutoModelForTokenClassification, create_optimizer, pipeline\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Load Data**"
      ],
      "metadata": {
        "id": "Eb98YXg1SLNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = load_dataset('conll2003')"
      ],
      "metadata": {
        "id": "jYdmn7cXRI05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset"
      ],
      "metadata": {
        "id": "9nWsK9TjSa0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141fd716-5dd9-4ea3-923b-5138e4988c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = raw_dataset['train'].features['ner_tags'].feature.names\n",
        "label_names"
      ],
      "metadata": {
        "id": "jXXpHR793waN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28067f0c-e572-4c03-81f2-0bc32791604c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Preprocess Data**"
      ],
      "metadata": {
        "id": "k2MgRNgH3r94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "Lq6xF2G0I4Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "  # For tokens inside a word and not at the beginning, replacing B-XXXX with I-XXXX by adding 1\n",
        "  new_labels = [-100 if word_id is None\n",
        "                else (labels[word_id] + (labels[word_id] % 2)) if (word_ids[i] == word_ids[i-1]) else labels[word_id]\n",
        "                for i, word_id in enumerate(word_ids)]\n",
        "  return new_labels"
      ],
      "metadata": {
        "id": "1ZgaGqgr7jUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "  tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
        "\n",
        "  new_labels = list()\n",
        "  for i, labels in enumerate(examples['ner_tags']):\n",
        "    word_ids = tokenized_inputs.word_ids(i)\n",
        "    new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "  tokenized_inputs['labels'] = new_labels\n",
        "  return tokenized_inputs"
      ],
      "metadata": {
        "id": "eTbOUKPmBU6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = raw_dataset.map(tokenize_and_align_labels, batched=True, remove_columns=raw_dataset['train'].column_names)"
      ],
      "metadata": {
        "id": "63FwUh41F2we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5bF_ofmBcGQ",
        "outputId": "8661bbe9-ef69-486e-f2f8-003de7537959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors='tf')\n",
        "\n",
        "tf_train_dataset = tokenized_dataset['train'].to_tf_dataset(\n",
        "    columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "tf_validation_dataset = tokenized_dataset['validation'].to_tf_dataset(\n",
        "    columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "tf_test_dataset = tokenized_dataset['test'].to_tf_dataset(\n",
        "    columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "FCIlKOg_IM2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Define Model**"
      ],
      "metadata": {
        "id": "ilK8RAtSKkA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {value: key for key, value in id2label.items()}"
      ],
      "metadata": {
        "id": "EtNX4owqSarT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModelForTokenClassification.from_pretrained(model_checkpoint, id2label=id2label, label2id=label2id)"
      ],
      "metadata": {
        "id": "FR7C4CxwSaon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.num_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TINWFAFgE9TV",
        "outputId": "f0bf7f04-4cb9-4464-c630-3a1b4a900290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Fine-tune the Model**"
      ],
      "metadata": {
        "id": "vebZcSpwMyIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training in mixed-precision float16\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "num_epochs = 5\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=2e-5,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=0,\n",
        "    weight_decay_rate=0.01\n",
        ")\n",
        "\n",
        "model.compile(optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=num_epochs, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK_09nj2E9RK",
        "outputId": "67acfe4c-4132-45fb-8d93-7a1494352955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "878/878 [==============================] - 216s 219ms/step - loss: 0.1718 - accuracy: 0.3762 - val_loss: 0.0583 - val_accuracy: 0.4419\n",
            "Epoch 2/5\n",
            "878/878 [==============================] - 196s 224ms/step - loss: 0.0450 - accuracy: 0.3921 - val_loss: 0.0557 - val_accuracy: 0.4423\n",
            "Epoch 3/5\n",
            "878/878 [==============================] - 196s 224ms/step - loss: 0.0257 - accuracy: 0.3952 - val_loss: 0.0549 - val_accuracy: 0.4428\n",
            "Epoch 4/5\n",
            "878/878 [==============================] - 197s 224ms/step - loss: 0.0165 - accuracy: 0.3940 - val_loss: 0.0561 - val_accuracy: 0.4431\n",
            "Epoch 5/5\n",
            "878/878 [==============================] - 196s 223ms/step - loss: 0.0108 - accuracy: 0.3977 - val_loss: 0.0587 - val_accuracy: 0.4432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Compute Metrics**"
      ],
      "metadata": {
        "id": "mm02pgxDRn2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load('seqeval')"
      ],
      "metadata": {
        "id": "f0yVWdhNE9Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions = list()\n",
        "all_labels = list()\n",
        "\n",
        "for batch in tf_test_dataset:\n",
        "  logits = model.predict_on_batch(batch)['logits']\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  labels = batch['labels']\n",
        "\n",
        "  for prediction, label in zip(predictions, labels):\n",
        "    for pred, lbl in zip(prediction, label):\n",
        "      if lbl == -100:\n",
        "        continue\n",
        "      all_predictions.append(label_names[pred])\n",
        "      all_labels.append(label_names[lbl])\n",
        "\n",
        "metric.compute(predictions=[all_predictions], references=[all_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap8M1HEvE9Lc",
        "outputId": "086e34e8-9a7b-4cf0-f266-85a14b00ddbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'precision': 0.9061771561771562,\n",
              "  'recall': 0.9322541966426858,\n",
              "  'f1': 0.9190307328605201,\n",
              "  'number': 1668},\n",
              " 'MISC': {'precision': 0.7234314980793854,\n",
              "  'recall': 0.8048433048433048,\n",
              "  'f1': 0.7619689817936615,\n",
              "  'number': 702},\n",
              " 'ORG': {'precision': 0.8567351598173516,\n",
              "  'recall': 0.9036724864539434,\n",
              "  'f1': 0.8795780837972459,\n",
              "  'number': 1661},\n",
              " 'PER': {'precision': 0.9451553930530164,\n",
              "  'recall': 0.9591836734693877,\n",
              "  'f1': 0.9521178637200736,\n",
              "  'number': 1617},\n",
              " 'overall_precision': 0.8780984719864177,\n",
              " 'overall_recall': 0.9157223796033994,\n",
              " 'overall_f1': 0.8965158606344253,\n",
              " 'overall_accuracy': 0.9716361229731646}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Predict using the Fine-tuned Model**"
      ],
      "metadata": {
        "id": "QEH478BzXVqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier = pipeline('token-classification', model=model, tokenizer=tokenizer, aggregation_strategy='simple')"
      ],
      "metadata": {
        "id": "mJ2hatYRE9I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier('Opel AG together with General Motors came in second place.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6mg5dgHE9GH",
        "outputId": "de88e710-c455-41ba-9330-385c9e69188f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'ORG',\n",
              "  'score': 0.99919504,\n",
              "  'word': 'Opel AG',\n",
              "  'start': 0,\n",
              "  'end': 7},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9992789,\n",
              "  'word': 'General Motors',\n",
              "  'start': 22,\n",
              "  'end': 36}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}