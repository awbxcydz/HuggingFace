{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Summarization**\n",
        "Text summarization is the task of condensing long documents into summaries. Summarization can be extractive summarization (extract the most relevant information from a document) or abstractive summarization (generate new text that captures the most relevant information).\n",
        "\n",
        "We shall fine-tune a mT5 model using TensorFlow on Multilingual Amazon Reviews Corpus to create a bilingual abstractive summarizer."
      ],
      "metadata": {
        "id": "NBk4FjJ-kpgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Install and Import Required Libraries**"
      ],
      "metadata": {
        "id": "STtFASPgkpZJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVL-XikB1Fhn"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers[sentencepiece] evaluate rouge_score nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import nltk\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, create_optimizer, pipeline\n",
        "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "hJMDDNglkqrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Load Data**"
      ],
      "metadata": {
        "id": "6xEXQphCBGBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset = load_dataset('amazon_reviews_multi', 'en')\n",
        "spanish_dataset = load_dataset('amazon_reviews_multi', 'es')"
      ],
      "metadata": {
        "id": "7y6zcxpDkqiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI4zjadWkqfF",
        "outputId": "72533cd9-7e94-474c-9eaf-918ea9c8c184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 200000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lwFA9CkkqcL",
        "outputId": "ba643b1c-5f02-45ef-cba5-1dece4e51313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 200000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Preprocess Data**"
      ],
      "metadata": {
        "id": "grtCSAK_BN9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset.set_format('pandas')\n",
        "english_df = english_dataset['train'][:]\n",
        "english_df['product_category'].value_counts()[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuUaGvjYkqXd",
        "outputId": "7db2507b-b44b-4774-be0c-f7beb172ea28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "home                      17679\n",
              "apparel                   15951\n",
              "wireless                  15717\n",
              "other                     13418\n",
              "beauty                    12091\n",
              "drugstore                 11730\n",
              "kitchen                   10382\n",
              "toy                        8745\n",
              "sports                     8277\n",
              "automotive                 7506\n",
              "lawn_and_garden            7327\n",
              "home_improvement           7136\n",
              "pet_products               7082\n",
              "digital_ebook_purchase     6749\n",
              "pc                         6401\n",
              "electronics                6186\n",
              "office_product             5521\n",
              "shoes                      5197\n",
              "grocery                    4730\n",
              "book                       3756\n",
              "Name: product_category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_dataset.set_format('pandas')\n",
        "spanish_df = spanish_dataset['train'][:]\n",
        "spanish_df['product_category'].value_counts()[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6osLCEfSkqRY",
        "outputId": "f900b5cf-6d7e-4006-9466-1a77929e0b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "home                        26962\n",
              "wireless                    25886\n",
              "toy                         13647\n",
              "sports                      13189\n",
              "pc                          11191\n",
              "home_improvement            10879\n",
              "electronics                 10385\n",
              "beauty                       7337\n",
              "automotive                   7143\n",
              "kitchen                      6695\n",
              "apparel                      5737\n",
              "drugstore                    5513\n",
              "book                         5264\n",
              "furniture                    5229\n",
              "baby_product                 4881\n",
              "office_product               4771\n",
              "lawn_and_garden              4237\n",
              "other                        3937\n",
              "pet_products                 3713\n",
              "personal_care_appliances     3573\n",
              "Name: product_category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_books(example):\n",
        "  return(example['product_category'] == 'book' or example['product_category'] == 'digital_ebook_purchase')\n",
        "\n",
        "english_dataset.reset_format()\n",
        "spanish_dataset.reset_format()\n",
        "\n",
        "english_books = english_dataset.filter(filter_books)\n",
        "spanish_books = spanish_dataset.filter(filter_books)"
      ],
      "metadata": {
        "id": "5ta7Y3xAtuZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating English and Spanish datasets\n",
        "books_dataset = DatasetDict()\n",
        "\n",
        "for split in english_books.keys():\n",
        "  books_dataset[split] = concatenate_datasets([english_books[split], spanish_books[split]])\n",
        "  books_dataset[split] = books_dataset[split].shuffle(seed=44)"
      ],
      "metadata": {
        "id": "IZi5vkHzxeGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering out examples with very short titles\n",
        "books_dataset = books_dataset.filter(lambda x: len(x['review_title'].split()) > 2)"
      ],
      "metadata": {
        "id": "x8VRcGHEr6u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'google/mt5-small'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "cRqcBhZ6xeAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 30\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  tokenized_inputs = tokenizer(examples['review_body'], max_length=max_input_length, truncation=True)\n",
        "  tokenized_labels = tokenizer(examples['review_title'], max_length=max_target_length, truncation=True)\n",
        "\n",
        "  tokenized_inputs['labels'] = tokenized_labels['input_ids']\n",
        "  return tokenized_inputs"
      ],
      "metadata": {
        "id": "3Lw4QmB3xd9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = books_dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "mASDa8q5bN4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o9d7QplBtsr",
        "outputId": "c5c81bf2-d701-4976-fd56-d24bf067a49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 9672\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 238\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 245\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors='tf')\n",
        "\n",
        "tf_train_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_dataset['train'],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "tf_validation_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_dataset['validation'],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "C1EzeIMTCE4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Create a Baseline**"
      ],
      "metadata": {
        "id": "eFpDt8Y3nsMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load('rouge')\n",
        "\n",
        "def three_sentence_summary(text):\n",
        "  return '\\n'.join(nltk.tokenize.sent_tokenize(text)[:3])\n",
        "\n",
        "def evaluate_baseline(dataset, metric):\n",
        "  summaries = [three_sentence_summary(text) for text in dataset['review_body']]\n",
        "  return metric.compute(predictions=summaries, references=dataset['review_title'])"
      ],
      "metadata": {
        "id": "G_ljmQ-RbOUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = evaluate_baseline(books_dataset['validation'], metric)\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCpKVllNpNav",
        "outputId": "22ed7065-600f-4a1e-d07d-badb48712161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 0.1680260170708547,\n",
              " 'rouge2': 0.088155998756527,\n",
              " 'rougeL': 0.1557126261248912,\n",
              " 'rougeLsum': 0.1599222144354075}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Fine-tune the Model**"
      ],
      "metadata": {
        "id": "N1wMiFklCXRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=5.6e-5,\n",
        "    num_train_steps = num_train_steps,\n",
        "    num_warmup_steps = 0,\n",
        "    weight_decay_rate=0.01\n",
        ")\n",
        "\n",
        "model.compile(optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jHwV7LNXpi2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training in mixed-precision float16\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "history = model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=num_epochs, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTikyCTkpizv",
        "outputId": "80f8d4c9-b39c-49e1-b892-dadfcc18f17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1209/1209 [==============================] - 437s 325ms/step - loss: 10.2651 - accuracy: 0.0406 - val_loss: 4.4493 - val_accuracy: 0.1354\n",
            "Epoch 2/5\n",
            "1209/1209 [==============================] - 388s 321ms/step - loss: 6.1472 - accuracy: 0.0725 - val_loss: 3.9019 - val_accuracy: 0.1740\n",
            "Epoch 3/5\n",
            "1209/1209 [==============================] - 389s 322ms/step - loss: 5.4112 - accuracy: 0.0953 - val_loss: 3.7000 - val_accuracy: 0.1895\n",
            "Epoch 4/5\n",
            "1209/1209 [==============================] - 387s 320ms/step - loss: 5.0311 - accuracy: 0.1116 - val_loss: 3.6177 - val_accuracy: 0.1945\n",
            "Epoch 5/5\n",
            "1209/1209 [==============================] - 389s 322ms/step - loss: 4.8781 - accuracy: 0.1193 - val_loss: 3.5898 - val_accuracy: 0.1980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Compute Metrics after Fine-tuning the Model**"
      ],
      "metadata": {
        "id": "A1z4Xxw6CkcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, pad_to_multiple_of=320, return_tensors='tf')\n",
        "\n",
        "tf_generate_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_dataset['validation'],\n",
        "    collate_fn=generation_data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size,\n",
        "    drop_remainder=True\n",
        ")\n",
        "\n",
        "@tf.function(jit_compile=True)\n",
        "def generate_with_xla(batch):\n",
        "  return model.generate(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], max_new_tokens=32)\n",
        "\n",
        "all_preds = list()\n",
        "all_labels = list()\n",
        "\n",
        "for batch, labels in tf_generate_dataset:\n",
        "  predictions = generate_with_xla(batch)\n",
        "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "  labels = labels.numpy()\n",
        "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "  decoded_preds = ['\\n'.join(nltk.tokenize.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "  decoded_labels = ['\\n'.join(nltk.tokenize.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "  all_preds.extend(decoded_preds)\n",
        "  all_labels.extend(decoded_labels)"
      ],
      "metadata": {
        "id": "BtHIxBiwpiw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "score"
      ],
      "metadata": {
        "id": "qdNg0bNNwrAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dce603d-fbe1-4d2a-8474-96b3738652b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 0.0638888888888889,\n",
              " 'rouge2': 0.0,\n",
              " 'rougeL': 0.0638888888888889,\n",
              " 'rougeLsum': 0.0638888888888889}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Predict using the Fine-tuned Model**"
      ],
      "metadata": {
        "id": "_V0yrMIJ3EES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline('summarization', model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "beNRgVs3wq80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_summary(idx):\n",
        "  review = books_dataset['test'][idx]['review_body']\n",
        "  title = books_dataset['test'][idx]['review_title']\n",
        "\n",
        "  prediction = summarizer(books_dataset['test'][idx]['review_body'])\n",
        "\n",
        "  print(f\"Review: {review}\")\n",
        "  print(f\"Title: {title}\")\n",
        "  print(f\"Summary: {prediction[0]['summary_text']}\")"
      ],
      "metadata": {
        "id": "hCpjJRpbwq5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_summary(10)"
      ],
      "metadata": {
        "id": "ashN6mnDBpII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04489ad9-0462-47a1-b347-e5150702a34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: HAPPY DANCE, HAPPY DANCE, HAPPY DANCE!!! This story is a rollercoaster ride of emotions. Here you have tragic events that ripped my heart out, then you have a swoon worthy romance that was sexy, sweet, and just made me believe in love, on to the nosey spiteful small town drama, heartbreak, and ending it all with a warm sweet feeling that I just didn't want to be over. Wyatt and Hannah are two of the most relatable characters that I have experienced this year. Out of all the books that I have read, these two rank pretty high in my memorable couples list. I just want more and more, I was so sad when I got to the end because I just wanted to keep their story going. This specific video review will be included in the October 2018 wrap-up. For other video book reviews check out my YouTube Channel: Steph's Rom Book Talk.\n",
            "Title: Hearts and Tears...So Amazing!\n",
            "Summary: A emotional story\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_summary(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXqXrPIeAegD",
        "outputId": "b1f5dff1-372c-44e9-ab1f-6aad9be102e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: Tras leer las numerosas críticas buenas sobre esta novela me animé a comprarla, y que largo se me ha hecho. La trama da giros sin sentido, sin explicar nada y dando todo por supuesto. Me ha dejado sin ganas de más.\n",
            "Title: Un poco decepcionante\n",
            "Summary: A poco de más\n"
          ]
        }
      ]
    }
  ]
}