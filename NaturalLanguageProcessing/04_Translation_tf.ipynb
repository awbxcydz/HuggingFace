{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Translation**\n",
        "Translation is the task of converting a sequence of text from one language to another. Translation systems are commonly used for translation between different language texts, but it can also be used for speech or some combination in between like text-to-speech or speech-to-text.\n",
        "\n",
        "We shall fine-tune a pretrained language translation model, \"opus-mt-en-fr\" from \"Helsinki-NLP\" using TensorFlow on KDE4 dataset."
      ],
      "metadata": {
        "id": "Zmc32j6yfWKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Install and Import Required Libraries**"
      ],
      "metadata": {
        "id": "njRnW1OrgUCk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe-vDVm009ta"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers[sentencepiece] evaluate sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, create_optimizer, pipeline\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "4pGVRm21gqfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Load Data**"
      ],
      "metadata": {
        "id": "70q1p9dtiBqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = load_dataset('kde4', lang1='en', lang2='fr')"
      ],
      "metadata": {
        "id": "a4d1gJgrhT1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyZ6Mhoohgid",
        "outputId": "1e43c6f7-91e4-400e-8d3e-985eff151bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 210173\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Preprocess Data**"
      ],
      "metadata": {
        "id": "0EpXbqfvh_VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = raw_dataset['train'].train_test_split(train_size=11000, test_size=1000, seed=44)\n",
        "test_dataset = split_dataset.pop('test')\n",
        "\n",
        "split_dataset = split_dataset['train'].train_test_split(train_size=10000, test_size=1000, seed=44)\n",
        "split_dataset['validation'] = split_dataset.pop('test')\n",
        "split_dataset['test'] = test_dataset"
      ],
      "metadata": {
        "id": "JFmxVOMohobE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFTdzkhKhoYE",
        "outputId": "c10a7008-cdfe-4dad-932f-b10fc3abf009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'Helsinki-NLP/opus-mt-en-fr'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors='pt')\n",
        "\n",
        "# Helsinki-NLP/opus-mt-en-fr checkpoint only has PyTorch weights\n",
        "# Library will automatically download and convert PyTorch weights on specifying from_pt=True\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=True)"
      ],
      "metadata": {
        "id": "mLfpj4JohoVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  inputs = [ex['en'] for ex in examples['translation']]\n",
        "  targets = [ex['fr'] for ex in examples['translation']]\n",
        "\n",
        "  result = tokenizer(inputs, text_target=targets, max_length=max_length, truncation=True)\n",
        "  return result"
      ],
      "metadata": {
        "id": "Oc7DZdezhoSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = split_dataset.map(preprocess_function, batched=True, remove_columns=split_dataset['train'].column_names)"
      ],
      "metadata": {
        "id": "5hKe9hxDhoPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewBM7jfk4Rup",
        "outputId": "0c29aee8-4db1-4d33-b0e2-76f22e644223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors='tf')\n",
        "\n",
        "tf_train_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_dataset['train'],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "tf_validation_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_dataset['validation'],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=16\n",
        ")"
      ],
      "metadata": {
        "id": "Jx41je-JhoKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Compute Metrics before Fine-tuning the Model**"
      ],
      "metadata": {
        "id": "KOpCPvW8s-17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load('sacrebleu')\n",
        "\n",
        "generation_data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, pad_to_multiple_of=128, return_tensors='tf')\n",
        "\n",
        "tf_generate_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_dataset['test'],\n",
        "    collate_fn=generation_data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=8\n",
        ")\n",
        "\n",
        "@tf.function(jit_compile=True)\n",
        "def generate_with_xla(batch):\n",
        "  return model.generate(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], max_new_tokens=128)\n",
        "\n",
        "def compute_metrics():\n",
        "  all_preds = list()\n",
        "  all_labels = list()\n",
        "\n",
        "  for batch, labels in tf_generate_dataset:\n",
        "    predictions = generate_with_xla(batch)\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    labels = labels.numpy()\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds] # predictions should be list of sentences for sacrebleu\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels] # references should be list of lists of sentences for sacrebleu\n",
        "    all_preds.extend(decoded_preds)\n",
        "    all_labels.extend(decoded_labels)\n",
        "\n",
        "  result = metric.compute(predictions=all_preds, references=all_labels)\n",
        "  return {'bleu': result['score']}"
      ],
      "metadata": {
        "id": "dYlD6Qzus91D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_metrics())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWNYV7QBmHGW",
        "outputId": "e65b7e38-b8f1-440d-f8b6-0c795900c2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu': 21.958967427031844}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Fine-tune the Model**"
      ],
      "metadata": {
        "id": "9YvJT5jxnJS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=5e-5,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=0,\n",
        "    weight_decay_rate=0.01\n",
        ")\n",
        "\n",
        "model.compile(optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8IfX72m5fVa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training in mixed-precision float16\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "history = model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=num_epochs, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UxVuATtfVX7",
        "outputId": "6e5dcea0-d8bd-40d4-ae08-d48872f8d10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "312/312 [==============================] - 245s 698ms/step - loss: 1.3971 - accuracy: 0.1243 - val_loss: 1.2503 - val_accuracy: 0.1736\n",
            "Epoch 2/5\n",
            "312/312 [==============================] - 212s 679ms/step - loss: 1.0161 - accuracy: 0.1335 - val_loss: 1.1926 - val_accuracy: 0.1760\n",
            "Epoch 3/5\n",
            "312/312 [==============================] - 207s 663ms/step - loss: 0.8370 - accuracy: 0.1423 - val_loss: 1.1836 - val_accuracy: 0.1763\n",
            "Epoch 4/5\n",
            "312/312 [==============================] - 209s 670ms/step - loss: 0.7253 - accuracy: 0.1435 - val_loss: 1.1858 - val_accuracy: 0.1767\n",
            "Epoch 5/5\n",
            "312/312 [==============================] - 208s 668ms/step - loss: 0.6596 - accuracy: 0.1458 - val_loss: 1.1851 - val_accuracy: 0.1771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Compute Metrics after Fine-tuning the Model**"
      ],
      "metadata": {
        "id": "1uJVEFsYnG6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_metrics())"
      ],
      "metadata": {
        "id": "Tl4uMYLqfVHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11048d49-6ee4-4520-9696-810bef6185f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu': 32.86650289193321}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Predict using the Fine-tuned Model**"
      ],
      "metadata": {
        "id": "YdPVbhk8mWyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline('translation', model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "3ny50xYKfVAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator('Default to expanded threads')"
      ],
      "metadata": {
        "id": "8ziEYP7Andtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a409a04-9a7c-4cbd-ffcb-d1da905e5465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Par défaut pour les fils étendus'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}